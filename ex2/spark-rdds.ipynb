{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T18:34:45.570093Z",
     "start_time": "2023-04-29T18:34:24.774496Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or retrieve a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ChiSquaredRDD\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Load the review file as an RDD\n",
    "# review_path = \"hdfs:///user/dic23_shared/amazon-reviews/full/reviewscombined.json\"\n",
    "review_path = \"hdfs:///user/dic23_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "# review_path = \"hdfs:///user/e11809642/reviews/reduced_devset.json\"\n",
    "input_rdd = sc.textFile(review_path)\n",
    "\n",
    "# Load the stopword file as a set\n",
    "stopwords_path = \"hdfs:///user/e11809642/stopwords.txt\"\n",
    "stopwords = set(sc.textFile(stopwords_path).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T18:34:45.585066Z",
     "start_time": "2023-04-29T18:34:45.573062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parse the JSON strings and extract the category and review text\n",
    "category_review_rdd = input_rdd \\\n",
    "    .map(lambda json_str: json.loads(json_str)) \\\n",
    "    .map(lambda json_obj: (json_obj['category'], json_obj['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T18:34:47.233787Z",
     "start_time": "2023-04-29T18:34:45.585066Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the total number of documents\n",
    "review_count = category_review_rdd.count()\n",
    "\n",
    "# Compute the number of documents in each category\n",
    "category_counts_rdd = category_review_rdd \\\n",
    "    .map(lambda pair: (pair[0], 1)) \\\n",
    "    .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T18:53:14.481513Z",
     "start_time": "2023-04-29T18:53:14.460034Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the chi-squared value for a given term and category\n",
    "def calculate_chi_square(term, category):\n",
    "    a = term_category_occurrences_rdd[(term, category)]\n",
    "    b = term_occurrences_rdd[term] - a\n",
    "    c = category_counts_rdd[category] - a\n",
    "    d = review_count - a - b - c\n",
    "    return review_count * (a * d - b * c) ** 2 / ((a + b) * (a + c) * (b + d) * (c + d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T18:49:17.576060Z",
     "start_time": "2023-04-29T18:49:07.069635Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the reviewText of each review based on a regex\n",
    "pattern = re.compile(r\"[^a-zA-Z<>^|]+\")\n",
    "\n",
    "# Compute the number of occurrences of each term in each category across all reviews\n",
    "term_category_occurrences_rdd = category_review_rdd \\\n",
    "    .map(lambda pair: ((pair[0], pair[1]), set(pattern.split(pair[1])))) \\\n",
    "    .flatMap(lambda pair: (((term.lower(), pair[0][0]), 1) for term in pair[1] if\n",
    "                           term.lower() not in stopwords and len(term) >= 2)) \\\n",
    "    .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# print(term_category_occurrences_rdd.take(10))\n",
    "\n",
    "# Compute the number of occurrences of each term across all reviews\n",
    "term_occurrences_rdd = term_category_occurrences_rdd \\\n",
    "    .map(lambda pair: (pair[0][0], pair[1])) \\\n",
    "    .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# print(term_occurrences_rdd.take(10))\n",
    "\n",
    "# Compute the chi-squared value for each unique term and category pair\n",
    "# (term, category) -> chi-square\n",
    "term_category_chi_squared_rdd = term_category_occurrences_rdd \\\n",
    "    .map(lambda pair: (pair[0][0], (pair[0][1], calculate_chi_square(pair[0][0], pair[0][1])))) \\\n",
    "    .groupByKey()\n",
    "\n",
    "# print(term_category_chi_squared_rdd.take(10))\n",
    "\n",
    "# Select the top 75 tokens with the highest chi-square value for each category\n",
    "# (category) -> [(token, chi-square)]\n",
    "chi_square_rdd = term_category_chi_squared_rdd \\\n",
    "    .map(lambda pair: (pair[0], sorted(pair[1], key=lambda x: x[1], reverse=True)[:75]))\n",
    "\n",
    "# Select all unique tokens from the top 75 tokens with the highest chi-square value for each category\n",
    "tokens = chi_square_rdd \\\n",
    "    .flatMap(lambda pair: (token for token, chi_square in pair[1])) \\\n",
    "    .distinct() \\\n",
    "    .collect()\n",
    "\n",
    "# Sort the tokens in alphabetical order\n",
    "tokens.sort()\n",
    "\n",
    "# Sort the categories in alphabetical order\n",
    "chi_square_rdd = chi_square_rdd.sortByKey()\n",
    "\n",
    "# Save the top 75 tokens with the highest chi-square value for each category to a file in the local file system\n",
    "# in the format: \"<category> term1:chi_squared1 term2:chi_squared2 ... term75:chi_squared75\" for each line and append the list of tokens to the end of the file\n",
    "with open(\"chi_squared.txt\", \"a\") as file:\n",
    "    for pair in chi_square_rdd.collect():\n",
    "        file.write(\"<%s>\" % pair[0] + \" \")\n",
    "        for token, chi_square in pair[1]:\n",
    "            file.write(\"%s:%f\" % (token, chi_square) + \" \")\n",
    "        file.write(\"\\n\")\n",
    "    file.write(\" \".join(tokens) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T18:34:23.445308Z",
     "start_time": "2023-04-29T18:34:22.817267Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC23)",
   "language": "python",
   "name": "python3_dic23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
