{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create or retrieve a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ChiSquaredRDD\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the 8-digit matriculation number with preceding e from the absolute path of the current working directory\n",
    "matriculation_number = re.search(r\"/e\\d{8}/\", os.getcwd()).group(0)[1:-1]\n",
    "\n",
    "# Put the stopwords file in the HDFS home directory for the current user (e.g. /user/e12345678/stopwords.txt)\n",
    "# Only do this if it does not already exist in the HDFS home directory\n",
    "if os.system(\"hdfs dfs -test -e /user/%s/stopwords.txt\" % matriculation_number):\n",
    "    os.system(\"hdfs dfs -put stopwords.txt /user/%s/stopwords.txt\" % matriculation_number)\n",
    "\n",
    "# Load the review file as an RDD\n",
    "# review_path = \"hdfs:///user/dic23_shared/amazon-reviews/full/reviewscombined.json\"\n",
    "review_path = \"hdfs:///user/dic23_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "input_rdd = sc.textFile(review_path)\n",
    "\n",
    "# Load the stopword file as a set\n",
    "stopwords_path = \"hdfs:///user/%s/stopwords.txt\" % matriculation_number\n",
    "stopwords = set(sc.textFile(stopwords_path).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON strings and extract the category and review text\n",
    "category_review_rdd = input_rdd \\\n",
    "    .map(lambda json_str: json.loads(json_str)) \\\n",
    "    .map(lambda json_obj: (json_obj['category'], json_obj['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the total number of documents\n",
    "review_count = category_review_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the number of documents in each category\n",
    "category_counts = category_review_rdd \\\n",
    "    .map(lambda pair: (pair[0], 1)) \\\n",
    "    .reduceByKey(lambda x, y: x + y) \\\n",
    "    .collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the reviewText of each review based on a regex\n",
    "pattern = re.compile(r\"[^a-zA-Z<>^|]+\")\n",
    "\n",
    "# Compute the number of occurrences of each term in each category across all reviews\n",
    "term_category_occurrences_rdd = category_review_rdd \\\n",
    "    .flatMap(\n",
    "    lambda pair: (((term.lower(), pair[0]), 1) for term in set(term.lower() for term in pattern.split(pair[1])) if\n",
    "                  term not in stopwords and len(term) >= 2)) \\\n",
    "    .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the number of occurrences of each term across all reviews\n",
    "term_occurrences_rdd = term_category_occurrences_rdd \\\n",
    "    .map(lambda pair: (pair[0][0], pair[1])) \\\n",
    "    .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine the number of occurrences of each term in each category with the number of occurrences of each term across all reviews\n",
    "# (term, category) -> (term_occurrences, term_category_occurrences)\n",
    "combined_rdd = term_category_occurrences_rdd \\\n",
    "    .map(lambda pair: (pair[0][0], (pair[0][1], pair[1]))) \\\n",
    "    .join(term_occurrences_rdd) \\\n",
    "    .map(lambda pair: ((pair[0], pair[1][0][0]), (pair[1][1], pair[1][0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the chi-squared value for a given term and category\n",
    "def calculate_chi_square(category, term_occurrences, term_category_occurrences):\n",
    "    a = term_category_occurrences\n",
    "    b = term_occurrences - a\n",
    "    c = category_counts[category] - a\n",
    "    d = review_count - a - b - c\n",
    "    return review_count * (a * d - b * c) ** 2 / ((a + b) * (a + c) * (b + d) * (c + d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the chi-squared value for each unique term and category pair\n",
    "# (category) -> [(term, chi-square)]\n",
    "term_category_chi_squared_rdd = combined_rdd \\\n",
    "    .map(lambda pair: (pair[0][1], (pair[0][0], calculate_chi_square(pair[0][1], pair[1][0], pair[1][1])))) \\\n",
    "    .groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the top 75 tokens with the highest chi-square value for each category and sort them in ascending order\n",
    "# (category) -> [(term, chi-square)]\n",
    "chi_square_rdd = term_category_chi_squared_rdd \\\n",
    "    .map(lambda pair: (pair[0], sorted(pair[1], key=lambda x: x[1], reverse=True)[:75])) \\\n",
    "    .sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select all unique tokens from the top 75 tokens with the highest chi-square value for each category\n",
    "tokens = chi_square_rdd \\\n",
    "    .flatMap(lambda pair: (token for token, chi_square in pair[1])) \\\n",
    "    .distinct() \\\n",
    "    .collect()\n",
    "\n",
    "# Sort the tokens in alphabetical order\n",
    "tokens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the top 75 tokens with the highest chi-square value for each category to a file in the local file system\n",
    "# in the format: \"<category> term1:chi_squared1 term2:chi_squared2 ... term75:chi_squared75\" for each line\n",
    "# and append the list of tokens to the end of the file\n",
    "with open(\"chi_squared.txt\", \"w\") as file:\n",
    "    for pair in chi_square_rdd.collect():\n",
    "        file.write(\"<%s>\" % pair[0] + \" \")\n",
    "        for token, chi_square in pair[1]:\n",
    "            file.write(\"%s:%f\" % (token, chi_square) + \" \")\n",
    "        file.write(\"\\n\")\n",
    "    file.write(\" \".join(tokens) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC23)",
   "language": "python",
   "name": "python3_dic23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
