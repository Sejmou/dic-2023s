{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 2: Datasets/DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:23.825933700Z",
     "start_time": "2023-05-31T21:30:22.840277Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import ChiSqSelector, RegexTokenizer, StringIndexer, IDF, StopWordsRemover, \\\n",
    "    Normalizer, CountVectorizer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, TrainValidationSplitModel\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:47.938195700Z",
     "start_time": "2023-05-31T21:30:23.828919200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a SparkSession with the name \"ChiSquaredPipeline\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ChiSquaredPipeline\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Retrieve the SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Set the log level to WARN\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.598111200Z",
     "start_time": "2023-05-31T21:30:47.945164100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the review file into a DataFrame\n",
    "# review_path = \"hdfs:///user/dic23_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "review_path = \"hdfs:///user/e11809642/reviews/reduced_devset.json\"\n",
    "# review_path = \"hdfs:///user/e11809642/reviews/tiny_devset.json\"\n",
    "df = spark.read.json(review_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.603108700Z",
     "start_time": "2023-05-31T21:30:56.599111600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the stopword file as a set from the local file system\n",
    "stopwords = set(open(\"stopwords.txt\").read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.753859100Z",
     "start_time": "2023-05-31T21:30:56.599111600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the review text into words using a regular expression pattern\n",
    "tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=\"[^a-zA-Z<>^|]+\", gaps=True,\n",
    "                           toLowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.758853500Z",
     "start_time": "2023-05-31T21:30:56.751857400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove stopwords from the tokenized words list using the stopword set\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=list(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.781864900Z",
     "start_time": "2023-05-31T21:30:56.757850400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the category column to a numeric type using the StringIndexer with alphabetically ascending order to allow for easy mapping to the category names later\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\", stringOrderType=\"alphabetAsc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.807336100Z",
     "start_time": "2023-05-31T21:30:56.781864900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the term frequency vector for each document (review)\n",
    "# tf = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "tf = CountVectorizer(inputCol=\"filtered\", outputCol=\"rawFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.821336400Z",
     "start_time": "2023-05-31T21:30:56.802332700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the inverse document frequency vector for each document (review)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select the top 2000 features based on the chi-squared test for feature independence\n",
    "css = ChiSqSelector(featuresCol=\"features\", outputCol=\"selectedFeatures\", labelCol=\"categoryIndex\", numTopFeatures=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create pipeline combining all steps\\n\",\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, indexer, tf, idf, css])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline to the DataFrame\n",
    "# model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the vocabulary and selected features\n",
    "# vocab = model.stages[3].vocabulary\n",
    "# selected_features = model.stages[5].selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the names of the selected features to a file sorted alphabetically in ascending order (space separated)\n",
    "# with open(\"output_ds.txt\", \"w\") as f:\n",
    "    # f.write(\" \".join(sorted([vocab[i] for i in selected_features])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.941049100Z",
     "start_time": "2023-05-31T21:30:56.863047300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into 80% training and 20% test data using a seed of 42\n",
    "training_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:56.947048500Z",
     "start_time": "2023-05-31T21:30:56.941049100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize each Vector using $L^2$ norm.\n",
    "normalizer = Normalizer(inputCol=\"selectedFeatures\", outputCol=\"normFeatures\", p=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:57.017426500Z",
     "start_time": "2023-05-31T21:30:56.953047400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create an SVM classifier using the normalized features and the category index\n",
    "svm = LinearSVC(featuresCol=\"normFeatures\", labelCol=\"categoryIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:57.021450900Z",
     "start_time": "2023-05-31T21:30:57.017426500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a one-vs-rest classifier using the SVM classifier\n",
    "ovr = OneVsRest(classifier=svm, featuresCol=\"normFeatures\", labelCol=\"categoryIndex\", parallelism=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:57.066421800Z",
     "start_time": "2023-05-31T21:30:57.022466Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a pipeline combining all steps\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, indexer, tf, idf, css, normalizer, ovr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:57.084328400Z",
     "start_time": "2023-05-31T21:30:57.061426100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create an evaluator using the F1-score metric\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:57.118493200Z",
     "start_time": "2023-05-31T21:30:57.104466600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a parameter grid for the SVM classifier with the following parameters:\n",
    "# - numTopFeatures: 50, 2000\n",
    "# - regParam: 0.1, 0.01, 0.001\n",
    "# - standardization: True, False\n",
    "# - maxIter: 10, 100\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(css.numTopFeatures, [50, 2000]) \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .addGrid(svm.standardization, [True, False]) \\\n",
    "    .addGrid(svm.maxIter, [10, 100]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:30:57.136471700Z",
     "start_time": "2023-05-31T21:30:57.110472700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a train-validation-split using the pipeline, parameter grid, and evaluator\n",
    "tvs = TrainValidationSplit(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, trainRatio=0.8,\n",
    "                           seed=42, parallelism=4, collectSubModels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fit the train-validation-split to the training data\n",
    "tvs_model = tvs.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Write the entire fitted tvs_model to disk\n",
    "tvs_model.write().overwrite().save(\"tvs_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:35:33.500569600Z",
     "start_time": "2023-05-31T21:30:57.130472200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the fitted tvs_model from disk\n",
    "tvs_model = TrainValidationSplitModel.load(\"tvs_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:35:41.364872300Z",
     "start_time": "2023-05-31T21:35:33.502710400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = tvs_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:05.894371400Z",
     "start_time": "2023-05-31T21:35:41.367897700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the micro-averaged F1-score for the predictions\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:05.899371600Z",
     "start_time": "2023-05-31T21:36:05.895367300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the validation metrics for each model trained in the train-validation-split\n",
    "results = tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:05.991204100Z",
     "start_time": "2023-05-31T21:36:05.903371700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with the parameter values and validation metrics for each model trained in the train-validation-split\n",
    "data = {}\n",
    "\n",
    "# Iterate over the parameter grid's parameter values and validation metrics\n",
    "for i, params in enumerate(param_grid):\n",
    "    # Iterate over the parameters in the parameter grid\n",
    "    for param_key, param_value in params.items():\n",
    "        # Add the parameter value to the dictionary\n",
    "        data.setdefault(param_key.name, []).append(param_value)\n",
    "    # Add the validation metric to the dictionary\n",
    "    data.setdefault(\"Evaluation Metric\", []).append(results[i])\n",
    "\n",
    "# Set the display options for Pandas\n",
    "pd.set_option('display.float_format', '{:.16g}'.format)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:07.199056500Z",
     "start_time": "2023-05-31T21:36:05.934203100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of category names sorted alphabetically in ascending order\n",
    "category_names = sorted([row[\"category\"] for row in df.select(\"category\").distinct().collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:07.210505Z",
     "start_time": "2023-05-31T21:36:07.202054900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of categories\n",
    "num_classes = len(category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:13.733279700Z",
     "start_time": "2023-05-31T21:36:07.210505Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate multiclass metrics for the test data\n",
    "metrics = MulticlassMetrics(predictions.select(\"prediction\", \"categoryIndex\").rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:20.319189300Z",
     "start_time": "2023-05-31T21:36:13.733279700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select the confusion matrix from the metrics object\n",
    "confusion_matrix = metrics.confusionMatrix()\n",
    "\n",
    "# Convert the confusion matrix to a Pandas DataFrame for better visualization mapping the category indices to the category names\n",
    "pd.DataFrame(confusion_matrix.toArray(), index=category_names, columns=category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:20.359186300Z",
     "start_time": "2023-05-31T21:36:20.319189300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect the F1-score for each category into a dataframe\n",
    "pd.DataFrame([(metrics.fMeasure(float(i))) for i in range(num_classes)], index=category_names, columns=[\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:20.359186300Z",
     "start_time": "2023-05-31T21:36:20.337186Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Print the macro-average f1-score using the test data\n",
    "print(\"Macro-Average F1 score: %f\" % (sum((metrics.fMeasure(float(i))) for i in range(num_classes)) / num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T21:36:21.187690400Z",
     "start_time": "2023-05-31T21:36:20.370181400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a cross-validator using the pipeline, parameter grid, and evaluator\n",
    "# cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Fit the cross-validator to the training data\n",
    "# cv_model = cv.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "# predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Compute the micro-averaged F1-score for the predictions\n",
    "# evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC23)",
   "language": "python",
   "name": "python3_dic23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
